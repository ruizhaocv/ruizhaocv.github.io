{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

# Selected Publications

Check out full publication list at my Google Scholar profile: 
<a href='https://scholar.google.com/citations?user=wYs7vogAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>.

[//]: # (Check out full publication list at my <a href='https://scholar.google.com/citations?user=wYs7vogAAAAJ'>Google Scholar profile</a>.)


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2025</div><a href="images/EvolveDirector.png"><img src='images/DoraCycle_teaser.png' alt="sym" width="100%"></a></div></div>
<div class='paper-box-text' markdown="1">

<b>DoraCycle: Domain-Oriented Adaptation of Unified Generative Model in Multimodal Cycles</b><br>
<i>The IEEE Conference on Computer Vision and Pattern Recognition, 2025</i><br>
<b>Rui Zhao</b>, Weijia Mao, Mike Zheng Shou.<br>
[<a href="https://arxiv.org/abs/2410.07133">arXiv</a>]
[[Github ![](https://img.shields.io/github/stars/showlab/DoraCycle?style=social)](https://github.com/showlab/DoraCycle)]<br>
<div style="text-align: justify">
  
</div>
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2024</div><a href="images/EvolveDirector.png"><img src='images/EvolveDirector.png' alt="sym" width="100%"></a></div></div>
<div class='paper-box-text' markdown="1">

<b>EvolveDirector: Approaching Advanced Text-to-Image Generation with Large Vision-Language Models</b><br>
<i>The Thirty-eighth Annual Conference on Neural Information Processing Systems, 2024</i><br>
<b>Rui Zhao</b>, Hangjie Yuan, Yujie Wei, Shiwei Zhang, Yuchao Gu, Lingmin Ran, Xiang Wang, Jay Wu, David Zhang, Yingya Zhang, Mike Zheng Shou.<br>
[<a href="https://arxiv.org/abs/2410.07133">arXiv</a>][<a href="https://huggingface.co/ruizhaocv/Edgen">Hugging Face</a>]
[[Github ![](https://img.shields.io/github/stars/showlab/EvolveDirector?style=social)](https://github.com/showlab/EvolveDirector)]<br>
<div style="text-align: justify">
  
</div>
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ECCV 2024</div><a href="images/MotionDirector_teaser.gif"><img src='images/MotionDirector_teaser.gif' alt="sym" width="100%"></a></div></div>
<div class='paper-box-text' markdown="1">

<b>MotionDirector: Motion Customization of Text-to-Video Diffusion Models</b><br>
<i>Proceedings of the European Conference on Computer Vision, 2024</i><br>
<b>Rui Zhao</b>, Yuchao Gu, Jay Zhangjie Wu, David Junhao Zhang, Jiawei Liu, Weijia Wu, Jussi Keppo, Mike Zheng Shou<br>
[<a href="https://showlab.github.io/MotionDirector/">Project Page</a>][<a href="https://arxiv.org/abs/2310.08465">arXiv</a>]
[[Github ![](https://img.shields.io/github/stars/showlab/MotionDirector?style=social)](https://github.com/showlab/MotionDirector)]<br>
🎙️ <b>Oral</b> Presentation, Acceptance Rate: 2.3%. <br>
🤗 Featured in Hugging Face "[Spaces of the Week 🔥](https://huggingface.co/spaces)" trending list. <br>
📃 Featured in "Top 40 most cited papers of ECCV 2024" [list](https://mp.weixin.qq.com/s/5FyBKVH4rc608MC84_-RdA) by AIR-SUN.
<div style="text-align: justify">
  
</div>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IJCV 2024</div><a href="images/Show1_teaser.gif"><img src='images/Show1_teaser.gif' alt="sym" width="100%"></a></div></div>
<div class='paper-box-text' markdown="1">

<b>Show-1: Marrying Pixel and Latent Diffusion Models for Text-to-Video Generation</b><br>
<i>International Journal of Computer Vision, 2024</i><br>
David Junhao Zhang<sup>†</sup>, Jay Zhangjie Wu<sup>†</sup>, Jia-Wei Liu<sup>†</sup>, <b>Rui Zhao</b>, Lingmin Ran, Yuchao Gu, Difei Gao, Mike Zheng Shou (<sup>†</sup>equal contribution)<br>
[<a href="https://showlab.github.io/Show-1/">Project Page</a>][<a href="https://arxiv.org/abs/2309.15818">arXiv</a>]
[[Github ![](https://img.shields.io/github/stars/showlab/Show-1?style=social)](https://github.com/showlab/Show-1)]<br>
<div style="text-align: justify">

</div>
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2023</div><a href="images/T2P_teaser.png"><img src='images/T2P_teaser.png' alt="sym" width="100%"></a></div></div>
<div class='paper-box-text' markdown="1">

<b>Zero-Shot Text-to-Parameter Translation for Game Character Auto-Creation</b><br>
<i>The IEEE Conference on Computer Vision and Pattern Recognition, 2023</i><br>
<b>Rui Zhao</b>, Wei Li, Zhipeng Hu, Lincheng Li, Zhengxia Zou, Zhenwei Shi, and Changjie Fan<br>
[<a href="https://arxiv.org/abs/2303.01311">PDF</a>]<br>
<div style="text-align: justify">
<b>Featured apps: </b> <a href="https://h.163.com/">Justice Mobile</a> (The first plausible solution for text-driven game characters auto-creation.).<br>

<b>Media coverage: </b><a href="https://www.newscientist.com/article/2362730-character-creator-ai-puts-barack-obama-or-anyone-in-a-video-game/">[NewScientist] Character creator AI puts Barack Obama – or anyone – in a video game</a> || 
<a href="https://news.yxrb.net/2023/0314/1372.html">[游戏日报] 网易伏羲“文字捏脸”方向论文入选CVPR会议，称已应用于《逆水寒手游》</a> || 
<a href="https://mp.weixin.qq.com/s/I4MVjk7rIZIl0g8OY6xobg">CVPR 2023 | 网易伏羲5篇论文入选 包含文字捏脸等业内首创工作</a> ||
<a href="https://automaton-media.com/articles/newsjp/20230314-240584/">[AUTOMATON] Researchers report technological breakthroughs in using AI to “make characters by asking with words”.</a> (in Japanese, for English version, please refer to <a href="https://www.newsdirectory3.com/researchers-report-technological-breakthroughs-in-using-ai-to-make-characters-by-asking-with-words-a-wide-range-of-text-can-be-identified-from-animals-to-celebrities-automaton/">reprint 1</a> and <a href="https://www.archyde.com/researchers-report-on-the-technological-achievements-of-using-ai-to-make-characters-just-by-asking-with-words-a-wide-range-of-text-can-be-specified-from-animals-to-celebrities-automaton/">reprint 2</a>) || 
<a href="https://nazology.net/archives/123271">[Nazology] "Character creation support AI" that creates the ideal face specified in the sentence is now available!</a> .<br>


</div>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TIP 2022</div><a href="images/SkyAR_teaser.png"><img src='images/SkyAR_teaser.png' alt="sym" width="100%"></a></div></div>
<div class='paper-box-text' markdown="1">
<b>Castle in the Sky: Dynamic Sky Replacement and Harmonization in Videos</b><br>
<i>IEEE Transactions on Image Processing, 2022</i><br>
Zhengxia Zou, <b>Rui Zhao</b>, Tianyang Shi, Shuang Qiu, and Zhenwei Shi<br>
[<a href="https://levir.buaa.edu.cn/publications/SkyAR.pdf">PDF</a>][<a href="https://jiupinjia.github.io/skyar/">Project Page</a>]
[[Github ![](https://img.shields.io/github/stars/jiupinjia/SkyAR?style=social)](https://github.com/jiupinjia/SkyAR)]<br>

<b>Featured apps: </b> <a href="https://wandb.ai/wandb/skyAR/reports/The-Sky-Is-In-Our-Grasp---VmlldzozMjY0NDI">Weights & Biases</a>, a ML developer tool with 100,000+ practitioners.<br>

<b>Media coverage: </b>
<a href="https://thenextweb.com/news/this-open-source-ai-tool-can-make-your-video-spectacular-with-sky-replacement-effects">[TNW] This open-source AI tool can make your video spectacular with sky replacement effects</a> || 
<a href="https://betterprogramming.pub/the-top-10-trending-machine-learning-projects-of-2020-d923bf31abb7">[Better Programming] The Top 10 Trending ML Projects of 2020</a>. <br>
<div style="text-align: justify">
</div>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TGRS 2021</div><a href="images/StructuredAttention.png"><img src='images/StructuredAttention.png' alt="sym" width="100%"></a></div></div>
<div class='paper-box-text' markdown="1">
<b>High-resolution remote sensing image captioning based on structured attention</b><br>
<i>IEEE Transactions on Geoscience and Remote Sensing, 2021</i><br>
<b>Rui Zhao</b>, Zhenwei Shi, and Zhengxia Zou<br>
[<a href="https://levir.buaa.edu.cn/publications/Structured_Attention.pdf">PDF</a>]<br>

🏆️ <b>ESI Highly Cited Paper</b>*<br>
<i>* received enough citations to place in the top 1% of the academic field of Geosciences based on publication year. [<a href="https://clarivate.libguides.com/c.php?g=593878&p=4107961">Clarivate</a>]</i><br>
<div style="text-align: justify">
</div>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">GRSL 2022</div><a href="images/RST2I.png"><img src='images/RST2I.png' alt="sym" width="100%"></a></div></div>
<div class='paper-box-text' markdown="1">
<b>Text to Remote Sensing Image Generation With Structured Generative Adversarial Networks</b><br>
<i>IEEE Geoscience and Remote Sensing Letters, 2022</i><br>
<b>Rui Zhao</b>, Zhenwei Shi<br>
[<a href="https://levir.buaa.edu.cn/publications/Text-to-Remote-Sensing-Image_Generation_With_Structured_Generative_Adversarial_Networks.pdf">PDF</a>]
<div style="text-align: justify">
</div>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">RS 2019</div><a href="images/E-CEM.png"><img src='images/E-CEM.png' alt="sym" width="100%"></a></div></div>
<div class='paper-box-text' markdown="1">
<b>Ensemble-based cascaded constrained energy minimization for hyperspectral target detection</b><br>
<i>Remote Sensing, 2019</i><br>
<b>Rui Zhao</b>, Zhenwei Shi, Zhengxia Zou, and Zhou Zhang<br>
[<a href="https://levir.buaa.edu.cn/publications/RemoteSensing2019-Zhao-Shi-Zou-Zhang.pdf">PDF</a>][<a href="https://github.com/ruizhaocv/E_CEM-for-Hyperspectral-Target-Detection">Code</a>] 
<div style="text-align: justify">
</div>
</div>
</div>

