{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

# Selected Publications

[//]: # (Check out full publication list at my Google Scholar profile: )

[//]: # (<a href='https://scholar.google.com/citations?user=wYs7vogAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>.)

[//]: # (Check out full publication list at my <a href='https://scholar.google.com/citations?user=wYs7vogAAAAJ'>Google Scholar profile</a>.)

### Video Generation & Editing:
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ECCV 2024</div><a href="images/MotionDirector_teaser.gif"><img src='images/MotionDirector_teaser.gif' alt="sym" width="100%"></a></div></div>
<div class='paper-box-text' markdown="1">

<b>MotionDirector: Motion Customization of Text-to-Video Diffusion Models</b><br>
<i>Proceedings of the European Conference on Computer Vision, 2024</i><br>
<b>Rui Zhao</b>, Yuchao Gu, Jay Zhangjie Wu, David Junhao Zhang, Jiawei Liu, Weijia Wu, Jussi Keppo, Mike Zheng Shou<br>
[<a href="https://showlab.github.io/MotionDirector/">Project Page</a>][<a href="https://arxiv.org/abs/2310.08465">arXiv</a>]
[[Github ![](https://img.shields.io/github/stars/showlab/MotionDirector?style=social)](https://github.com/showlab/MotionDirector)]<br>
<div style="text-align: justify">

</div>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">arXiv</div><a href="images/Show1_teaser.gif"><img src='images/Show1_teaser.gif' alt="sym" width="100%"></a></div></div>
<div class='paper-box-text' markdown="1">

<b>Show-1: Marrying Pixel and Latent Diffusion Models for Text-to-Video Generation</b><br>
<i>arXiv, 2023</i><br>
David Junhao Zhang<sup>â€ </sup>, Jay Zhangjie Wu<sup>â€ </sup>, Jia-Wei Liu<sup>â€ </sup>, <b>Rui Zhao</b>, Lingmin Ran, Yuchao Gu, Difei Gao, Mike Zheng Shou (<sup>â€ </sup>equal contribution)<br>
[<a href="https://showlab.github.io/Show-1/">Project Page</a>][<a href="https://arxiv.org/abs/2309.15818">arXiv</a>]
[[Github ![](https://img.shields.io/github/stars/showlab/Show-1?style=social)](https://github.com/showlab/Show-1)]<br>
<div style="text-align: justify">

</div>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TIP 2022</div><a href="images/SkyAR_teaser.png"><img src='images/SkyAR_teaser.png' alt="sym" width="100%"></a></div></div>
<div class='paper-box-text' markdown="1">
<b>Castle in the Sky: Dynamic Sky Replacement and Harmonization in Videos</b><br>
<i>IEEE Transactions on Image Processing, 2022</i><br>
Zhengxia Zou, <b>Rui Zhao</b>, Tianyang Shi, Shuang Qiu, and Zhenwei Shi<br>
[<a href="https://levir.buaa.edu.cn/publications/SkyAR.pdf">PDF</a>][<a href="https://jiupinjia.github.io/skyar/">Project Page</a>]
[[Github ![](https://img.shields.io/github/stars/jiupinjia/SkyAR?style=social)](https://github.com/jiupinjia/SkyAR)]<br>

<b>Featured apps: </b> <a href="https://wandb.ai/wandb/skyAR/reports/The-Sky-Is-In-Our-Grasp---VmlldzozMjY0NDI">Weights & Biases</a>, a ML developer tool with 100,000+ practitioners.<br>

<b>Media coverage: </b>
<a href="https://thenextweb.com/news/this-open-source-ai-tool-can-make-your-video-spectacular-with-sky-replacement-effects">[TNW] This open-source AI tool can make your video spectacular with sky replacement effects</a> || 
<a href="https://betterprogramming.pub/the-top-10-trending-machine-learning-projects-of-2020-d923bf31abb7">[Better Programming] The Top 10 Trending ML Projects of 2020</a>. <br>
<div style="text-align: justify">
</div>
</div>
</div>

### Avatar Generation:

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2023</div><a href="images/T2P_teaser.png"><img src='images/T2P_teaser.png' alt="sym" width="100%"></a></div></div>
<div class='paper-box-text' markdown="1">

<b>Zero-Shot Text-to-Parameter Translation for Game Character Auto-Creation</b><br>
<i>The IEEE Conference on Computer Vision and Pattern Recognition, 2023</i><br>
<b>Rui Zhao</b>, Wei Li, Zhipeng Hu, Lincheng Li, Zhengxia Zou, Zhenwei Shi, and Changjie Fan<br>
[<a href="https://arxiv.org/abs/2303.01311">PDF</a>]<br>
<div style="text-align: justify">
<b>Featured apps: </b> <a href="https://h.163.com/">Justice Mobile</a> (The first plausible solution for text-driven game characters auto-creation.).<br>

<b>Media coverage: </b><a href="https://www.newscientist.com/article/2362730-character-creator-ai-puts-barack-obama-or-anyone-in-a-video-game/">[NewScientist] Character creator AI puts Barack Obama â€“ or anyone â€“ in a video game</a> || 
<a href="https://news.yxrb.net/2023/0314/1372.html">[æ¸¸æˆæ—¥æŠ¥] ç½‘æ˜“ä¼ç¾²â€œæ–‡å­—æè„¸â€æ–¹å‘è®ºæ–‡å…¥é€‰CVPRä¼šè®®ï¼Œç§°å·²åº”ç”¨äºã€Šé€†æ°´å¯’æ‰‹æ¸¸ã€‹</a> || 
<a href="https://mp.weixin.qq.com/s/I4MVjk7rIZIl0g8OY6xobg">CVPR 2023 | ç½‘æ˜“ä¼ç¾²5ç¯‡è®ºæ–‡å…¥é€‰ åŒ…å«æ–‡å­—æè„¸ç­‰ä¸šå†…é¦–åˆ›å·¥ä½œ</a> ||
<a href="https://automaton-media.com/articles/newsjp/20230314-240584/">[AUTOMATON] Researchers report technological breakthroughs in using AI to â€œmake characters by asking with wordsâ€.</a> (in Japanese, for English version, please refer to <a href="https://www.newsdirectory3.com/researchers-report-technological-breakthroughs-in-using-ai-to-make-characters-by-asking-with-words-a-wide-range-of-text-can-be-identified-from-animals-to-celebrities-automaton/">reprint 1</a> and <a href="https://www.archyde.com/researchers-report-on-the-technological-achievements-of-using-ai-to-make-characters-just-by-asking-with-words-a-wide-range-of-text-can-be-specified-from-animals-to-celebrities-automaton/">reprint 2</a>) || 
<a href="https://nazology.net/archives/123271">[Nazology] "Character creation support AI" that creates the ideal face specified in the sentence is now available!</a> .<br>


</div>
</div>
</div>

### Image Captioning & Generation:
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TGRS 2021</div><a href="images/StructuredAttention.png"><img src='images/StructuredAttention.png' alt="sym" width="100%"></a></div></div>
<div class='paper-box-text' markdown="1">
<b>High-resolution remote sensing image captioning based on structured attention</b><br>
<i>IEEE Transactions on Geoscience and Remote Sensing, 2021</i><br>
<b>Rui Zhao</b>, Zhenwei Shi, and Zhengxia Zou<br>
[<a href="https://levir.buaa.edu.cn/publications/Structured_Attention.pdf">PDF</a>]<br>

ğŸ†ï¸ <b>ESI Highly Cited Paper</b>*<br>
<i>* received enough citations to place in the top 1% of the academic field of Geosciences based on publication year. [<a href="https://clarivate.libguides.com/c.php?g=593878&p=4107961">Clarivate</a>]</i><br>
<div style="text-align: justify">
</div>
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TGRS 2022</div><a href="images/RSICC_teaser.png"><img src='images/RSICC_teaser.png' alt="sym" width="100%"></a></div></div>
<div class='paper-box-text' markdown="1">
<b>Remote Sensing Image Change Captioning With Dual-Branch Transformers: A New Method and a Large Scale Dataset</b><br>
<i>IEEE Transactions on Geoscience and Remote Sensing, 2022</i><br>
Chenyang Liu, <b>Rui Zhao</b>, Hao Chen, Zhengxia Zou, and Zhenwei Shi<br>
[<a href="https://levir.buaa.edu.cn/publications/ChangeCaptioning.pdf">PDF</a>] [<a href="https://github.com/Chen-Yang-Liu/RSICC">Dataset</a>] [<a href="https://github.com/Chen-Yang-Liu/RSICC">Code</a>] 
<div style="text-align: justify">
</div>
</div>
</div>
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">GRSL 2022</div><a href="images/RST2I.png"><img src='images/RST2I.png' alt="sym" width="100%"></a></div></div>
<div class='paper-box-text' markdown="1">
<b>Text to Remote Sensing Image Generation With Structured Generative Adversarial Networks</b><br>
<i>IEEE Geoscience and Remote Sensing Letters, 2022</i><br>
<b>Rui Zhao</b>, Zhenwei Shi<br>
[<a href="https://levir.buaa.edu.cn/publications/Text-to-Remote-Sensing-Image_Generation_With_Structured_Generative_Adversarial_Networks.pdf">PDF</a>]
<div style="text-align: justify">
</div>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">RS 2019</div><a href="images/E-CEM.png"><img src='images/E-CEM.png' alt="sym" width="100%"></a></div></div>
<div class='paper-box-text' markdown="1">
<b>Ensemble-based cascaded constrained energy minimization for hyperspectral target detection</b><br>
<i>Remote Sensing, 2019</i><br>
<b>Rui Zhao</b>, Zhenwei Shi, Zhengxia Zou, and Zhou Zhang<br>
[<a href="https://levir.buaa.edu.cn/publications/RemoteSensing2019-Zhao-Shi-Zou-Zhang.pdf">PDF</a>][<a href="https://github.com/ruizhaocv/E_CEM-for-Hyperspectral-Target-Detection">Code</a>] 
<div style="text-align: justify">
</div>
</div>
</div>


